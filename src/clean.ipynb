{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fuzzy_cache = {}\n",
    "\n",
    "df_car_sales = pd.read_csv('../dataset/vehicles.csv')\n",
    "df_car_details = pd.read_json('../dataset/vehicle_details.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a small sample of the data for testing\n",
    "# Store processed data to prevent reload\n",
    "sample_df_sales = df_car_sales.sample(n=10000).reset_index(drop=True)\n",
    "# sample_df_sales = df_car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car_sales['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 - Select relevant columns\n",
    "We start by selecting only the relevant columns from the `sample_df_sales` and `df_details` dataframes. This step ensures that we focus on the necessary information for further processing and analysis. Irrelevant or redundant columns are dropped to streamline the workflow and reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def select_columns(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Preprocess the sales and details dataframes by dropping irrelevant columns,\n",
    "    removing rows with suspicious values, and normalizing the posting_date column.\n",
    "\n",
    "    Parameters:\n",
    "    df_sales (pd.DataFrame): The sales dataframe.\n",
    "    df_details (pd.DataFrame): The details dataframe.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: The preprocessed sales and details dataframes.\n",
    "    \"\"\"\n",
    "    # Select relevant columns\n",
    "    df_data = df_data[['region', 'price', 'year', 'manufacturer', 'model', \n",
    "                         'condition', 'cylinders', 'fuel', 'odometer', \n",
    "                         'title_status', 'transmission', 'drive', 'size', 'type', \n",
    "                         'paint_color', 'state', 'posting_date']]\n",
    "    # Useful details columns\n",
    "    # df_details = df_details[['make', 'model', 'year', 'pv4', 'lv4', \n",
    "    #                      'displ', 'fuelcost08', 'yousavespend', 'fescore', \n",
    "    #                      'ghgscore', 'barrels08', 'co2tailpipegpm', 'vclass', \n",
    "    #                      'highway08', 'uhighway', 'comb08', 'ghgscorea', 'cylinders']]\n",
    "\n",
    "    return df_data, df_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 - Fill the car details with actual data\n",
    "The `sample_df_sales` may have missing data or information that doesn't match the model of the car. We can fill that information using `df_details`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use a dictionary to store previously seen matches\n",
    "\n",
    "def get_matched_models(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Perform fuzzy matching to match makes and models between sample_df_sales and df_details.\n",
    "\n",
    "    Parameters:\n",
    "    sample_df_sales (pd.DataFrame): The sales dataframe containing manufacturer and model information.\n",
    "    df_details (pd.DataFrame): The details dataframe containing make and model information.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The updated sample_df_sales dataframe with matched_make and matched_model columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_closest_match(row, column, choices):\n",
    "        if pd.isnull(row[column]) or row[column] == '':\n",
    "            return None\n",
    "        value = row[column]\n",
    "        if value in fuzzy_cache:\n",
    "            return fuzzy_cache[value]\n",
    "        match, score = process.extractOne(value, choices)\n",
    "        result = match if score > 80 else None\n",
    "        fuzzy_cache[value] = result\n",
    "        return result\n",
    "\n",
    "    # Apply fuzzy matching for manufacturer first\n",
    "    df_details['make'] = df_details['make'].str.lower()\n",
    "    \n",
    "    # Add a progress bar to the process\n",
    "    tqdm.pandas(desc=\"Matching manufacturers\")\n",
    "    df_data['matched_make'] = df_data.progress_apply(\n",
    "        lambda row: get_closest_match(row, 'manufacturer', df_details['make'].unique()), axis=1\n",
    "    )\n",
    "\n",
    "    # Filter df_details to only include rows with the matched manufacturer\n",
    "    def filter_models(row):\n",
    "        if pd.isnull(row['matched_make']):\n",
    "            return np.array([])  # Return an empty NumPy array\n",
    "        return df_details[df_details['make'] == row['matched_make']]['model'].unique()\n",
    "\n",
    "    # Apply fuzzy matching for model based on the filtered models\n",
    "    def get_closest_model(row):\n",
    "        models = filter_models(row)\n",
    "        if models.size == 0:  # Explicitly check if the array is empty\n",
    "            return None\n",
    "        return get_closest_match(row, 'model', models)\n",
    "\n",
    "    # Add a progress bar to the process\n",
    "    tqdm.pandas(desc=\"Matching models\")\n",
    "    df_data['matched_model'] = df_data.progress_apply(get_closest_model, axis=1)\n",
    "\n",
    "    # Calculate the number of matched and unmatched rows\n",
    "    matched_count = df_data['matched_model'].notnull().sum()\n",
    "    print(f\"Matched: {matched_count} out of {len(df_data)} rows\")\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "    \n",
    "def fill_model_deps(data_df, deps):\n",
    "        \"\"\"\n",
    "        Fill missing values in model-dependent columns using the mode of data grouped by various keys.\n",
    "\n",
    "        Parameters:\n",
    "        df (pd.DataFrame): The dataframe to process.\n",
    "        columns (list): List of model-dependent columns to fill.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: The dataframe with missing values filled.\n",
    "        \"\"\"\n",
    "        # Fill missing values grouped by manufacturer, model, and year\n",
    "        for col in deps:\n",
    "            data_df[col] = data_df.groupby(['manufacturer', 'model', 'year'])[col].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "            )\n",
    "\n",
    "        # Fill missing values grouped by manufacturer and model\n",
    "        for col in deps:\n",
    "            data_df[col] = data_df.groupby(['manufacturer', 'model'])[col].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "            )\n",
    "\n",
    "        # Fill missing values grouped by matched_make, matched_model, and year\n",
    "        for col in deps:\n",
    "            data_df[col] = data_df.groupby(['matched_make', 'matched_model', 'year'])[col].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "            )\n",
    "\n",
    "        # Fill missing values grouped by matched_make and matched_model\n",
    "        for col in deps:\n",
    "            data_df[col] = data_df.groupby(['matched_make', 'matched_model'])[col].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "            )\n",
    "\n",
    "        return data_df\n",
    "    \n",
    "def fill_non_deps(data_df, deps):\n",
    "    # Define model-dependent columns\n",
    "\n",
    "    # Select columns to impute (excluding model-dependent columns)\n",
    "    columns_to_impute = [col for col in data_df.columns if col not in deps]\n",
    "\n",
    "    # Impute missing values using K-Means clustering\n",
    "\n",
    "    # Select numeric columns for clustering\n",
    "    numeric_cols = data_df.select_dtypes(include=[np.number]).columns\n",
    "    data_for_clustering = data_df[numeric_cols]\n",
    "\n",
    "    # Impute missing values with the mean before clustering\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data_imputed = imputer.fit_transform(data_for_clustering)\n",
    "\n",
    "    # Apply K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=data_df['type'].nunique(), random_state=42)\n",
    "    clusters = kmeans.fit_predict(data_imputed)\n",
    "\n",
    "    # Add cluster labels to the dataframe\n",
    "    data_df['cluster'] = clusters\n",
    "\n",
    "    # Impute missing values in the original dataframe using cluster means\n",
    "    for col in columns_to_impute:\n",
    "        if data_df[col].dtype in [np.float64, np.int64]:  # Numeric columns\n",
    "            data_df[col] = data_df.groupby('cluster')[col].transform(\n",
    "                lambda x: x.fillna(x.mean())\n",
    "            )\n",
    "        elif data_df[col].dtype == object:  # Categorical columns\n",
    "            data_df[col] = data_df.groupby('cluster')[col].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "            )\n",
    "            \n",
    "    # Drop the cluster column\n",
    "    data_df.drop(columns=['cluster'], inplace=True)\n",
    "    \n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_details(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Fill missing values in target columns of df_data using corresponding source columns from df_details,\n",
    "    and analyze categorical columns in the updated dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    df_data (pd.DataFrame): The sales dataframe.\n",
    "    df_details (pd.DataFrame): The details dataframe.\n",
    "    columns_to_fill (dict): A dictionary where keys are target columns in df_data and values are source columns in df_details.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The updated dataframe with filled values.\n",
    "    \"\"\"\n",
    "    columns_to_fill = {\n",
    "        'cylinders': 'cylinders_y',\n",
    "        'fuel': 'fueltype1',\n",
    "        'transmission': 'trany',\n",
    "        'type': 'vclass'\n",
    "    }\n",
    "    \n",
    "    # Convert matching columns to lowercase for consistent comparison\n",
    "    df_data['matched_make'] = df_data['matched_make'].str.lower()\n",
    "    df_data['matched_model'] = df_data['matched_model'].str.lower()\n",
    "    df_details['make'] = df_details['make'].str.lower()\n",
    "    df_details['model'] = df_details['model'].str.lower()\n",
    "    \n",
    "    df_details.drop_duplicates(subset=['make', 'model', 'year'], inplace=True)\n",
    "    \n",
    "    # Merge the dataframes on relevant keys\n",
    "    merged_df = pd.merge(df_data, df_details, how='left', left_on=['matched_make', 'matched_model', 'year'], right_on=['make','model','year'])[columns_to_fill.values()]\n",
    "\n",
    "    # Fill missing values in target columns using corresponding source columns\n",
    "    for target_col, source_col in columns_to_fill.items():\n",
    "        df_data[target_col] = df_data[target_col].fillna(merged_df[source_col])\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_values(df):\n",
    "    \"\"\"\n",
    "    Clean and preprocess specific columns in the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataframe to clean.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The cleaned dataframe.\n",
    "    \"\"\"\n",
    "    # Clean the 'cylinders' column to keep only numeric values\n",
    "    df['cylinders'] = df['cylinders'].str.extract(r'(\\d+)').astype('Int64')\n",
    "    df['transmission'] = df['transmission'].str.split(' ').str[0].str.lower()\n",
    "\n",
    "    # Group the 'fuel' column into broader categories\n",
    "    fuel_mapping = {\n",
    "        'gas': 'gasoline',\n",
    "        'Regular Gasoline': 'gasoline',\n",
    "        'Premium Gasoline': 'gasoline',\n",
    "        'Midgrade Gasoline': 'gasoline',\n",
    "        'diesel': 'diesel',\n",
    "        'Diesel': 'diesel',\n",
    "        'electric': 'electricity',\n",
    "        'Electricity': 'electricity',\n",
    "        'hybrid': 'hybrid'\n",
    "    }\n",
    "    df['fuel'] = df['fuel'].map(fuel_mapping).fillna(df['fuel'])\n",
    "\n",
    "    # Group the 'type' column into broader categories\n",
    "    type_mapping = {\n",
    "        'sedan': 'car',\n",
    "        'coupe': 'car',\n",
    "        'convertible': 'car',\n",
    "        'hatchback': 'car',\n",
    "        'wagon': 'car',\n",
    "        'Midsize Cars': 'car',\n",
    "        'Compact Cars': 'car',\n",
    "        'Large Cars': 'car',\n",
    "        'Subcompact Cars': 'car',\n",
    "        'Minicompact Cars': 'car',\n",
    "        'Two Seaters': 'car',\n",
    "        'SUV': 'suv',\n",
    "        'Sport Utility Vehicle - 4WD': 'suv',\n",
    "        'Sport Utility Vehicle - 2WD': 'suv',\n",
    "        'Small Sport Utility Vehicle 4WD': 'suv',\n",
    "        'Small Sport Utility Vehicle 2WD': 'suv',\n",
    "        'Standard Sport Utility Vehicle 4WD': 'suv',\n",
    "        'Standard Sport Utility Vehicle 2WD': 'suv',\n",
    "        'Special Purpose Vehicles': 'suv',\n",
    "        'Special Purpose Vehicle 4WD': 'suv',\n",
    "        'Special Purpose Vehicle 2WD': 'suv',\n",
    "        'offroad': 'suv',\n",
    "        'pickup': 'truck',\n",
    "        'truck': 'truck',\n",
    "        'Standard Pickup Trucks 4WD': 'truck',\n",
    "        'Standard Pickup Trucks 2WD': 'truck',\n",
    "        'Small Pickup Trucks 4WD': 'truck',\n",
    "        'Small Pickup Trucks 2WD': 'truck',\n",
    "        'Small Pickup Trucks': 'truck',\n",
    "        'Standard Pickup Trucks': 'truck',\n",
    "        'mini-van': 'van',\n",
    "        'van': 'van',\n",
    "        'bus': 'van',\n",
    "        'Minivan - 2WD': 'van',\n",
    "        'Minivan - 4WD': 'van',\n",
    "        'Vans': 'van',\n",
    "        'Vans, Cargo Type': 'van',\n",
    "        'Vans, Passenger Type': 'van',\n",
    "        'Small Station Wagons': 'car',\n",
    "        'Midsize Station Wagons': 'car'\n",
    "    }\n",
    "    df['type'] = df['type'].map(type_mapping).fillna(df['type'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_data(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Clean the sales and details dataframes by removing rows with missing values\n",
    "    and resetting the index.\n",
    "\n",
    "    Parameters:\n",
    "    df_data (pd.DataFrame): The sales dataframe.\n",
    "    df_details (pd.DataFrame): The details dataframe.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: The cleaned sales and details dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select relevant columns\n",
    "    df_data, df_details = select_columns(df_data, df_details)\n",
    "    \n",
    "    # Replace 'other' values with NaN\n",
    "    df_data.replace('other', np.nan, inplace=True)\n",
    "    \n",
    "    # Merge the dataframes to get more details\n",
    "    df_data = get_matched_models(df_data, df_details)\n",
    "    df_data = df_data[~df_data['matched_make'].isnull() & ~df_data['matched_model'].isnull()]\n",
    "    \n",
    "    # model_dependent_columns = ['cylinders', 'fuel', 'transmission', 'drive', 'size', 'type']\n",
    "    model_dependent_columns = df_data\n",
    "    \n",
    "    # Fill model dependent values using df_details\n",
    "    df_data = fill_details(df_data, df_details)\n",
    "    df_data = group_values(df_data)\n",
    "\n",
    "    # Fill model dependent values using modes of each model\n",
    "    df_data = fill_model_deps(df_data, model_dependent_columns)\n",
    "    # df_data = fill_non_deps(df_data, model_dependent_columns)\n",
    "    \n",
    "    df_data = df_data.dropna()\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = clean_data(sample_df_sales, df_car_details)\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('../dataset/cleaned_sales_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
