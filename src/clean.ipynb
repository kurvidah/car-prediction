{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_sales = pd.read_csv('../dataset/vehicles.csv')\n",
    "df_details = pd.read_json('../dataset/vehicle_details.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a small sample of the data for testing\n",
    "# Store processed data to prevent reload\n",
    "sample_df_sales = df_sales.sample(n=10000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 - Select relevant columns\n",
    "We start by selecting only the relevant columns from the `sample_df_sales` and `df_details` dataframes. This step ensures that we focus on the necessary information for further processing and analysis. Irrelevant or redundant columns are dropped to streamline the workflow and reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def select_columns(df, df_details):\n",
    "    \"\"\"\n",
    "    Preprocess the sales and details dataframes by dropping irrelevant columns,\n",
    "    removing rows with suspicious values, and normalizing the posting_date column.\n",
    "\n",
    "    Parameters:\n",
    "    df_sales (pd.DataFrame): The sales dataframe.\n",
    "    df_details (pd.DataFrame): The details dataframe.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: The preprocessed sales and details dataframes.\n",
    "    \"\"\"\n",
    "    # Select relevant columns\n",
    "    df = df[['region', 'price', 'year', 'manufacturer', 'model', \n",
    "                         'condition', 'cylinders', 'fuel', 'odometer', \n",
    "                         'title_status', 'transmission', 'drive', 'type', \n",
    "                         'paint_color', 'state', 'posting_date']]\n",
    "    # Useful details columns\n",
    "    df_details = df_details[['make', 'model', 'pv4', 'lv4', \n",
    "                         'displ', 'fuelcost08', 'yousavespend', 'fescore', \n",
    "                         'ghgscore', 'barrels08', 'co2tailpipegpm', 'vclass', \n",
    "                         'highway08', 'uhighway', 'comb08', 'ghgscorea']]\n",
    "\n",
    "    return df, df_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 - Fill the car details with actual data\n",
    "The `sample_df_sales` may have missing data or information that doesn't match the model of the car. We can fill that information using `df_details`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use a dictionary to store previously seen matches\n",
    "fuzzy_cache = {}\n",
    "\n",
    "def get_matched_models(df, df_details):\n",
    "    \"\"\"\n",
    "    Perform fuzzy matching to match makes and models between sample_df_sales and df_details.\n",
    "\n",
    "    Parameters:\n",
    "    sample_df_sales (pd.DataFrame): The sales dataframe containing manufacturer and model information.\n",
    "    df_details (pd.DataFrame): The details dataframe containing make and model information.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The updated sample_df_sales dataframe with matched_make and matched_model columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_closest_match(row, column, choices):\n",
    "        if pd.isnull(row[column]):\n",
    "            return None\n",
    "        value = row[column]\n",
    "        if value in fuzzy_cache:\n",
    "            return fuzzy_cache[value]\n",
    "        match, score = process.extractOne(value, choices)\n",
    "        result = match if score > 80 else None\n",
    "        fuzzy_cache[value] = result\n",
    "        return result\n",
    "\n",
    "    # Apply fuzzy matching for manufacturer first\n",
    "    df_details.loc[:, 'make'] = df_details['make'].str.lower()\n",
    "    \n",
    "    # Add a progress bar to the process\n",
    "    tqdm.pandas(desc=\"Matching manufacturers\")\n",
    "    df.loc[:, 'matched_make'] = df.apply(\n",
    "        lambda row: get_closest_match(row, 'manufacturer', df_details['make'].unique()), axis=1\n",
    "    )\n",
    "\n",
    "    # Filter df_details to only include rows with the matched manufacturer\n",
    "    def filter_models(row):\n",
    "        if pd.isnull(row['matched_make']):\n",
    "            return np.array([])  # Return an empty NumPy array\n",
    "        return df_details[df_details['make'] == row['matched_make']]['model'].unique()\n",
    "\n",
    "    # Apply fuzzy matching for model based on the filtered models\n",
    "    def get_closest_model(row):\n",
    "        models = filter_models(row)\n",
    "        if models.size == 0:  # Explicitly check if the array is empty\n",
    "            return None\n",
    "        return get_closest_match(row, 'model', models)\n",
    "\n",
    "    # Add a progress bar to the process\n",
    "    tqdm.pandas(desc=\"Matching models\")\n",
    "    df['matched_model'] = df.progress_apply(get_closest_model, axis=1)\n",
    "\n",
    "    # Calculate the number of matched and unmatched rows\n",
    "    matched_count = df['matched_model'].notnull().sum()\n",
    "    print(f\"Matched: {matched_count} out of {len(df)} rows\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Clean the sales and details dataframes by removing rows with missing values\n",
    "    and resetting the index.\n",
    "\n",
    "    Parameters:\n",
    "    df_data (pd.DataFrame): The sales dataframe.\n",
    "    df_details (pd.DataFrame): The details dataframe.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: The cleaned sales and details dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select relevant columns\n",
    "    df_data, df_details = select_columns(df_data, df_details)\n",
    "    \n",
    "    # Merge the dataframes to get more details\n",
    "    df_data = get_matched_models(df_data, df_details)\n",
    "    df_data = df_data.merge(\n",
    "        df_details,\n",
    "        left_on=['matched_make', 'matched_model'],\n",
    "        right_on=['make', 'model'],\n",
    "        how='left',\n",
    "        suffixes=('', '_details')\n",
    "    )\n",
    "    df_data = df_data.drop(columns=['matched_make', 'matched_model', 'make', 'model_details'])\n",
    "    \n",
    "    # Impute missing values\n",
    "    numeric_columns = df_data.select_dtypes(include=[np.number]).columns\n",
    "    categorical_columns = df_data.select_dtypes(include=[object]).columns\n",
    "    \n",
    "    # Fill missing numeric values with the median\n",
    "    df_data[numeric_columns] = df_data[numeric_columns].fillna(df_data[numeric_columns].median())\n",
    "\n",
    "    # Fill missing categorical values with the mode\n",
    "    df_data[categorical_columns] = df_data[categorical_columns].fillna(df_data[categorical_columns].mode().iloc[0])\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hikar\\AppData\\Local\\Temp\\ipykernel_26588\\1037086581.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'matched_make'] = df.apply(\n",
      "Matching models: 100%|██████████| 10000/10000 [01:43<00:00, 96.54it/s]\n",
      "C:\\Users\\hikar\\AppData\\Local\\Temp\\ipykernel_26588\\1037086581.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['matched_model'] = df.progress_apply(get_closest_model, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: 8892 out of 10000 rows\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376219 entries, 0 to 376218\n",
      "Data columns (total 30 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   region          376219 non-null  object \n",
      " 1   price           376219 non-null  int64  \n",
      " 2   year            376219 non-null  float64\n",
      " 3   manufacturer    376219 non-null  object \n",
      " 4   model           376219 non-null  object \n",
      " 5   condition       376219 non-null  object \n",
      " 6   cylinders       376219 non-null  object \n",
      " 7   fuel            376219 non-null  object \n",
      " 8   odometer        376219 non-null  float64\n",
      " 9   title_status    376219 non-null  object \n",
      " 10  transmission    376219 non-null  object \n",
      " 11  drive           376219 non-null  object \n",
      " 12  type            376219 non-null  object \n",
      " 13  paint_color     376219 non-null  object \n",
      " 14  state           376219 non-null  object \n",
      " 15  posting_date    376219 non-null  object \n",
      " 16  pv4             376219 non-null  float64\n",
      " 17  lv4             376219 non-null  float64\n",
      " 18  displ           376219 non-null  float64\n",
      " 19  fuelcost08      376219 non-null  float64\n",
      " 20  yousavespend    376219 non-null  float64\n",
      " 21  fescore         376219 non-null  float64\n",
      " 22  ghgscore        376219 non-null  float64\n",
      " 23  barrels08       376219 non-null  float64\n",
      " 24  co2tailpipegpm  376219 non-null  float64\n",
      " 25  vclass          376219 non-null  object \n",
      " 26  highway08       376219 non-null  float64\n",
      " 27  uhighway        376219 non-null  float64\n",
      " 28  comb08          376219 non-null  float64\n",
      " 29  ghgscorea       376219 non-null  float64\n",
      "dtypes: float64(15), int64(1), object(14)\n",
      "memory usage: 86.1+ MB\n"
     ]
    }
   ],
   "source": [
    "sample_df_sales = clean_data(sample_df_sales, df_details)\n",
    "sample_df_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_sales.to_csv('../dataset/cleaned_sales_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
