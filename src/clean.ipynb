{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fuzzy_cache = {}\n",
    "\n",
    "df_car_sales = pd.read_csv('../dataset/vehicles.csv')\n",
    "df_car_details = pd.read_json('../dataset/vehicle_details.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a small sample of the data for testing\n",
    "# Store processed data to prevent reload\n",
    "sample_df_sales = df_car_sales.sample(n=10000).reset_index(drop=True)\n",
    "# sample_df_sales = df_car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "sedan          87056\n",
       "SUV            77284\n",
       "pickup         43510\n",
       "truck          35279\n",
       "other          22110\n",
       "coupe          19204\n",
       "hatchback      16598\n",
       "wagon          10751\n",
       "van             8548\n",
       "convertible     7731\n",
       "mini-van        4825\n",
       "offroad          609\n",
       "bus              517\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_car_sales['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 - Select relevant columns\n",
    "We start by selecting only the relevant columns from the `sample_df_sales` and `df_details` dataframes. This step ensures that we focus on the necessary information for further processing and analysis. Irrelevant or redundant columns are dropped to streamline the workflow and reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def select_columns(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Preprocess the sales and details dataframes by dropping irrelevant columns,\n",
    "    removing rows with suspicious values, and normalizing the posting_date column.\n",
    "\n",
    "    Parameters:\n",
    "    df_sales (pd.DataFrame): The sales dataframe.\n",
    "    df_details (pd.DataFrame): The details dataframe.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: The preprocessed sales and details dataframes.\n",
    "    \"\"\"\n",
    "    # Select relevant columns\n",
    "    df_data = df_data[['region', 'price', 'year', 'manufacturer', 'model', \n",
    "                         'condition', 'cylinders', 'fuel', 'odometer', \n",
    "                         'title_status', 'transmission', 'drive', 'size', 'type', \n",
    "                         'paint_color', 'state', 'posting_date']]\n",
    "    # Useful details columns\n",
    "    # df_details = df_details[['make', 'model', 'year', 'pv4', 'lv4', \n",
    "    #                      'displ', 'fuelcost08', 'yousavespend', 'fescore', \n",
    "    #                      'ghgscore', 'barrels08', 'co2tailpipegpm', 'vclass', \n",
    "    #                      'highway08', 'uhighway', 'comb08', 'ghgscorea', 'cylinders']]\n",
    "\n",
    "    return df_data, df_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 - Fill the car details with actual data\n",
    "The `sample_df_sales` may have missing data or information that doesn't match the model of the car. We can fill that information using `df_details`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use a dictionary to store previously seen matches\n",
    "\n",
    "def get_matched_models(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Perform fuzzy matching to match makes and models between sample_df_sales and df_details.\n",
    "\n",
    "    Parameters:\n",
    "    sample_df_sales (pd.DataFrame): The sales dataframe containing manufacturer and model information.\n",
    "    df_details (pd.DataFrame): The details dataframe containing make and model information.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The updated sample_df_sales dataframe with matched_make and matched_model columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_closest_match(row, column, choices):\n",
    "        if pd.isnull(row[column]):\n",
    "            return None\n",
    "        value = row[column]\n",
    "        if value in fuzzy_cache:\n",
    "            return fuzzy_cache[value]\n",
    "        match, score = process.extractOne(value, choices)\n",
    "        result = match if score > 80 else None\n",
    "        fuzzy_cache[value] = result\n",
    "        return result\n",
    "\n",
    "    # Apply fuzzy matching for manufacturer first\n",
    "    df_details['make'] = df_details['make'].str.lower()\n",
    "    \n",
    "    # Add a progress bar to the process\n",
    "    tqdm.pandas(desc=\"Matching manufacturers\")\n",
    "    df_data['matched_make'] = df_data.progress_apply(\n",
    "        lambda row: get_closest_match(row, 'manufacturer', df_details['make'].unique()), axis=1\n",
    "    )\n",
    "\n",
    "    # Filter df_details to only include rows with the matched manufacturer\n",
    "    def filter_models(row):\n",
    "        if pd.isnull(row['matched_make']):\n",
    "            return np.array([])  # Return an empty NumPy array\n",
    "        return df_details[df_details['make'] == row['matched_make']]['model'].unique()\n",
    "\n",
    "    # Apply fuzzy matching for model based on the filtered models\n",
    "    def get_closest_model(row):\n",
    "        models = filter_models(row)\n",
    "        if models.size == 0:  # Explicitly check if the array is empty\n",
    "            return None\n",
    "        return get_closest_match(row, 'model', models)\n",
    "\n",
    "    # Add a progress bar to the process\n",
    "    tqdm.pandas(desc=\"Matching models\")\n",
    "    df_data['matched_model'] = df_data.progress_apply(get_closest_model, axis=1)\n",
    "\n",
    "    # Calculate the number of matched and unmatched rows\n",
    "    matched_count = df_data['matched_model'].notnull().sum()\n",
    "    print(f\"Matched: {matched_count} out of {len(df_data)} rows\")\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "    \n",
    "def fill_model_deps(data_df, deps):\n",
    "        \"\"\"\n",
    "        Fill missing values in model-dependent columns using the mode of data grouped by various keys.\n",
    "\n",
    "        Parameters:\n",
    "        df (pd.DataFrame): The dataframe to process.\n",
    "        columns (list): List of model-dependent columns to fill.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: The dataframe with missing values filled.\n",
    "        \"\"\"\n",
    "        # Fill missing values grouped by manufacturer, model, and year\n",
    "        for col in deps:\n",
    "            data_df[col] = data_df.groupby(['manufacturer', 'model', 'year'])[col].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "            )\n",
    "\n",
    "        # Fill missing values grouped by manufacturer and model\n",
    "        for col in deps:\n",
    "            data_df[col] = data_df.groupby(['manufacturer', 'model'])[col].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "            )\n",
    "\n",
    "        # Fill missing values grouped by matched_make, matched_model, and year\n",
    "        for col in deps:\n",
    "            data_df[col] = data_df.groupby(['matched_make', 'matched_model', 'year'])[col].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "            )\n",
    "\n",
    "        # Fill missing values grouped by matched_make and matched_model\n",
    "        for col in deps:\n",
    "            data_df[col] = data_df.groupby(['matched_make', 'matched_model'])[col].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "            )\n",
    "\n",
    "        return data_df\n",
    "    \n",
    "def fill_non_deps(data_df, deps):\n",
    "    # Define model-dependent columns\n",
    "\n",
    "    # Select columns to impute (excluding model-dependent columns)\n",
    "    columns_to_impute = [col for col in data_df.columns if col not in deps]\n",
    "\n",
    "    # Impute missing values using K-Means clustering\n",
    "\n",
    "    # Select numeric columns for clustering\n",
    "    numeric_cols = data_df.select_dtypes(include=[np.number]).columns\n",
    "    data_for_clustering = data_df[numeric_cols]\n",
    "\n",
    "    # Impute missing values with the mean before clustering\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data_imputed = imputer.fit_transform(data_for_clustering)\n",
    "\n",
    "    # Apply K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=data_df['type'].nunique(), random_state=42)\n",
    "    clusters = kmeans.fit_predict(data_imputed)\n",
    "\n",
    "    # Add cluster labels to the dataframe\n",
    "    data_df['cluster'] = clusters\n",
    "\n",
    "    # Impute missing values in the original dataframe using cluster means\n",
    "    for col in columns_to_impute:\n",
    "        if data_df[col].dtype in [np.float64, np.int64]:  # Numeric columns\n",
    "            data_df[col] = data_df.groupby('cluster')[col].transform(\n",
    "                lambda x: x.fillna(x.mean())\n",
    "            )\n",
    "        elif data_df[col].dtype == object:  # Categorical columns\n",
    "            data_df[col] = data_df.groupby('cluster')[col].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "            )\n",
    "            \n",
    "    # Drop the cluster column\n",
    "    data_df.drop(columns=['cluster'], inplace=True)\n",
    "    \n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_details(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Fill missing values in target columns of df_data using corresponding source columns from df_details,\n",
    "    and analyze categorical columns in the updated dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    df_data (pd.DataFrame): The sales dataframe.\n",
    "    df_details (pd.DataFrame): The details dataframe.\n",
    "    columns_to_fill (dict): A dictionary where keys are target columns in df_data and values are source columns in df_details.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The updated dataframe with filled values.\n",
    "    \"\"\"\n",
    "    columns_to_fill = {\n",
    "        'cylinders': 'cylinders_y',\n",
    "        'fuel': 'fueltype1',\n",
    "        'transmission': 'trany',\n",
    "        'type': 'vclass'\n",
    "    }\n",
    "    \n",
    "    # Convert matching columns to lowercase for consistent comparison\n",
    "    df_data['matched_make'] = df_data['matched_make'].str.lower()\n",
    "    df_data['matched_model'] = df_data['matched_model'].str.lower()\n",
    "    df_details['make'] = df_details['make'].str.lower()\n",
    "    df_details['model'] = df_details['model'].str.lower()\n",
    "    \n",
    "    # Merge the dataframes on relevant keys\n",
    "    merged_df = pd.merge(df_data, df_details, how='left', left_on=['matched_make', 'matched_model', 'year'], right_on=['make','model','year'])[columns_to_fill.values()]\n",
    "\n",
    "    # Fill missing values in target columns using corresponding source columns\n",
    "    for target_col, source_col in columns_to_fill.items():\n",
    "        df_data[target_col] = df_data[target_col].fillna(merged_df[source_col])\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_values(df):\n",
    "    \"\"\"\n",
    "    Clean and preprocess specific columns in the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataframe to clean.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The cleaned dataframe.\n",
    "    \"\"\"\n",
    "    # Clean the 'cylinders' column to keep only numeric values\n",
    "    df['cylinders'] = df['cylinders'].str.extract(r'(\\d+)').astype('Int64')\n",
    "    df['transmission'] = df['transmission'].str.split(' ').str[0].str.lower()\n",
    "\n",
    "    # Group the 'fuel' column into broader categories\n",
    "    fuel_mapping = {\n",
    "        'gas': 'gasoline',\n",
    "        'Regular Gasoline': 'gasoline',\n",
    "        'Premium Gasoline': 'gasoline',\n",
    "        'Midgrade Gasoline': 'gasoline',\n",
    "        'diesel': 'diesel',\n",
    "        'Diesel': 'diesel',\n",
    "        'electric': 'electricity',\n",
    "        'Electricity': 'electricity',\n",
    "        'hybrid': 'hybrid'\n",
    "    }\n",
    "    df['fuel'] = df['fuel'].map(fuel_mapping).fillna(df['fuel'])\n",
    "\n",
    "    # Group the 'type' column into broader categories\n",
    "    type_mapping = {\n",
    "        'sedan': 'car',\n",
    "        'coupe': 'car',\n",
    "        'convertible': 'car',\n",
    "        'hatchback': 'car',\n",
    "        'wagon': 'car',\n",
    "        'Midsize Cars': 'car',\n",
    "        'Compact Cars': 'car',\n",
    "        'Large Cars': 'car',\n",
    "        'Subcompact Cars': 'car',\n",
    "        'Minicompact Cars': 'car',\n",
    "        'Two Seaters': 'car',\n",
    "        'SUV': 'suv',\n",
    "        'Sport Utility Vehicle - 4WD': 'suv',\n",
    "        'Sport Utility Vehicle - 2WD': 'suv',\n",
    "        'Small Sport Utility Vehicle 4WD': 'suv',\n",
    "        'Small Sport Utility Vehicle 2WD': 'suv',\n",
    "        'Standard Sport Utility Vehicle 4WD': 'suv',\n",
    "        'Standard Sport Utility Vehicle 2WD': 'suv',\n",
    "        'Special Purpose Vehicles': 'suv',\n",
    "        'Special Purpose Vehicle 4WD': 'suv',\n",
    "        'Special Purpose Vehicle 2WD': 'suv',\n",
    "        'offroad': 'suv',\n",
    "        'pickup': 'truck',\n",
    "        'truck': 'truck',\n",
    "        'Standard Pickup Trucks 4WD': 'truck',\n",
    "        'Standard Pickup Trucks 2WD': 'truck',\n",
    "        'Small Pickup Trucks 4WD': 'truck',\n",
    "        'Small Pickup Trucks 2WD': 'truck',\n",
    "        'Small Pickup Trucks': 'truck',\n",
    "        'Standard Pickup Trucks': 'truck',\n",
    "        'mini-van': 'van',\n",
    "        'van': 'van',\n",
    "        'bus': 'van',\n",
    "        'Minivan - 2WD': 'van',\n",
    "        'Minivan - 4WD': 'van',\n",
    "        'Vans': 'van',\n",
    "        'Vans, Cargo Type': 'van',\n",
    "        'Vans, Passenger Type': 'van',\n",
    "        'Small Station Wagons': 'car',\n",
    "        'Midsize Station Wagons': 'car'\n",
    "    }\n",
    "    df['type'] = df['type'].map(type_mapping).fillna(df['type'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_data(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Clean the sales and details dataframes by removing rows with missing values\n",
    "    and resetting the index.\n",
    "\n",
    "    Parameters:\n",
    "    df_data (pd.DataFrame): The sales dataframe.\n",
    "    df_details (pd.DataFrame): The details dataframe.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: The cleaned sales and details dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select relevant columns\n",
    "    df_data, df_details = select_columns(df_data, df_details)\n",
    "    \n",
    "    # Replace 'other' values with NaN\n",
    "    df_data.replace('other', np.nan, inplace=True)\n",
    "    \n",
    "    # Merge the dataframes to get more details\n",
    "    df_data = get_matched_models(df_data, df_details)\n",
    "    df_data = df_data[~df_data['matched_make'].isnull() & ~df_data['matched_model'].isnull()]\n",
    "    \n",
    "    # model_dependent_columns = ['cylinders', 'fuel', 'transmission', 'drive', 'size', 'type']\n",
    "    model_dependent_columns = df_data\n",
    "    \n",
    "    # Fill model dependent values using df_details\n",
    "    df_data = fill_details(df_data, df_details)\n",
    "    df_data = group_values(df_data)\n",
    "\n",
    "    # Fill model dependent values using modes of each model\n",
    "    df_data = fill_model_deps(df_data, model_dependent_columns)\n",
    "    # df_data = fill_non_deps(df_data, model_dependent_columns)\n",
    "    \n",
    "    df_data = df_data.dropna()\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3934/580873449.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_data.replace('other', np.nan, inplace=True)\n",
      "Matching manufacturers: 100%|██████████| 10000/10000 [00:23<00:00, 428.92it/s]\n",
      "/tmp/ipykernel_3934/2044057230.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_data['matched_make'] = df_data.progress_apply(\n",
      "Matching models: 100%|██████████| 10000/10000 [01:11<00:00, 140.40it/s]\n",
      "/tmp/ipykernel_3934/2044057230.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_data['matched_model'] = df_data.progress_apply(get_closest_model, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: 8868 out of 10000 rows\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17607 entries, 0 to 17606\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   cylinders_y  14274 non-null  float64\n",
      " 1   fueltype1    14311 non-null  object \n",
      " 2   trany        14311 non-null  object \n",
      " 3   vclass       14311 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 550.3+ KB\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df_clean = clean_data(sample_df_sales, df_car_details)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdf_clean\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "df_clean = clean_data(sample_df_sales, df_car_details)\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "sedan                                 1805\n",
       "SUV                                   1627\n",
       "pickup                                 842\n",
       "truck                                  665\n",
       "Midsize Cars                           397\n",
       "coupe                                  345\n",
       "hatchback                              265\n",
       "Compact Cars                           240\n",
       "van                                    174\n",
       "wagon                                  162\n",
       "Large Cars                             149\n",
       "Subcompact Cars                        143\n",
       "convertible                            117\n",
       "Standard Pickup Trucks 4WD             116\n",
       "mini-van                               115\n",
       "Small Sport Utility Vehicle 2WD        101\n",
       "Small Sport Utility Vehicle 4WD         99\n",
       "Sport Utility Vehicle - 4WD             70\n",
       "Sport Utility Vehicle - 2WD             60\n",
       "Two Seaters                             51\n",
       "Standard Pickup Trucks 2WD              47\n",
       "Small Pickup Trucks 4WD                 38\n",
       "Small Station Wagons                    33\n",
       "Standard Sport Utility Vehicle 4WD      29\n",
       "Minivan - 2WD                           25\n",
       "Small Pickup Trucks 2WD                 24\n",
       "Standard Sport Utility Vehicle 2WD      21\n",
       "Special Purpose Vehicle 2WD             16\n",
       "Minicompact Cars                         9\n",
       "Special Purpose Vehicles                 9\n",
       "offroad                                  8\n",
       "Standard Pickup Trucks                   7\n",
       "bus                                      4\n",
       "Vans, Cargo Type                         3\n",
       "Special Purpose Vehicle 4WD              3\n",
       "Small Pickup Trucks                      2\n",
       "Midsize Station Wagons                   2\n",
       "Vans                                     1\n",
       "Minivan - 4WD                            1\n",
       "Vans, Passenger Type                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('../dataset/cleaned_sales_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
