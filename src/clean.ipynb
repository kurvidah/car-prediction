{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_car_sales = pd.read_csv('../dataset/vehicles.csv')\n",
    "df_car_details = pd.read_json('../dataset/vehicle_details.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a small sample of the data for testing\n",
    "# Store processed data to prevent reload\n",
    "sample_df_sales = df_car_sales.sample(n=50000).reset_index(drop=True)\n",
    "# sample_df_sales = df_car_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 - Select relevant columns\n",
    "We start by selecting only the relevant columns from the `sample_df_sales` and `df_details` dataframes. This step ensures that we focus on the necessary information for further processing and analysis. Irrelevant or redundant columns are dropped to streamline the workflow and reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def select_columns(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Preprocess the sales and details dataframes by dropping irrelevant columns,\n",
    "    removing rows with suspicious values, and normalizing the posting_date column.\n",
    "\n",
    "    Parameters:\n",
    "    df_sales (pd.DataFrame): The sales dataframe.\n",
    "    df_details (pd.DataFrame): The details dataframe.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: The preprocessed sales and details dataframes.\n",
    "    \"\"\"\n",
    "    # Select relevant columns\n",
    "    df_data = df_data[['region', 'price', 'year', 'manufacturer', 'model', \n",
    "                         'condition', 'cylinders', 'fuel', 'odometer', \n",
    "                         'title_status', 'transmission', 'drive', 'type', \n",
    "                         'paint_color', 'state', 'posting_date']]\n",
    "    # Useful details columns\n",
    "    df_details = df_details[['make', 'model', 'year', 'pv4', 'lv4', \n",
    "                         'displ', 'fuelcost08', 'yousavespend', 'fescore', \n",
    "                         'ghgscore', 'barrels08', 'co2tailpipegpm', 'vclass', \n",
    "                         'highway08', 'uhighway', 'comb08', 'ghgscorea']]\n",
    "\n",
    "    return df_data, df_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 - Fill the car details with actual data\n",
    "The `sample_df_sales` may have missing data or information that doesn't match the model of the car. We can fill that information using `df_details`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use a dictionary to store previously seen matches\n",
    "fuzzy_cache = {}\n",
    "\n",
    "def get_matched_models(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Perform fuzzy matching to match makes and models between sample_df_sales and df_details.\n",
    "\n",
    "    Parameters:\n",
    "    sample_df_sales (pd.DataFrame): The sales dataframe containing manufacturer and model information.\n",
    "    df_details (pd.DataFrame): The details dataframe containing make and model information.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The updated sample_df_sales dataframe with matched_make and matched_model columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_closest_match(row, column, choices):\n",
    "        if pd.isnull(row[column]):\n",
    "            return None\n",
    "        value = row[column]\n",
    "        if value in fuzzy_cache:\n",
    "            return fuzzy_cache[value]\n",
    "        match, score = process.extractOne(value, choices)\n",
    "        result = match if score > 80 else None\n",
    "        fuzzy_cache[value] = result\n",
    "        return result\n",
    "\n",
    "    # Apply fuzzy matching for manufacturer first\n",
    "    df_details['make'] = df_details['make'].str.lower()\n",
    "    \n",
    "    # Add a progress bar to the process\n",
    "    tqdm.pandas(desc=\"Matching manufacturers\")\n",
    "    df_data['matched_make'] = df_data.apply(\n",
    "        lambda row: get_closest_match(row, 'manufacturer', df_details['make'].unique()), axis=1\n",
    "    )\n",
    "\n",
    "    # Filter df_details to only include rows with the matched manufacturer\n",
    "    def filter_models(row):\n",
    "        if pd.isnull(row['matched_make']):\n",
    "            return np.array([])  # Return an empty NumPy array\n",
    "        return df_details[df_details['make'] == row['matched_make']]['model'].unique()\n",
    "\n",
    "    # Apply fuzzy matching for model based on the filtered models\n",
    "    def get_closest_model(row):\n",
    "        models = filter_models(row)\n",
    "        if models.size == 0:  # Explicitly check if the array is empty\n",
    "            return None\n",
    "        return get_closest_match(row, 'model', models)\n",
    "\n",
    "    # Add a progress bar to the process\n",
    "    tqdm.pandas(desc=\"Matching models\")\n",
    "    df_data['matched_model'] = df_data.progress_apply(get_closest_model, axis=1)\n",
    "\n",
    "    # Calculate the number of matched and unmatched rows\n",
    "    matched_count = df_data['matched_model'].notnull().sum()\n",
    "    print(f\"Matched: {matched_count} out of {len(df_data)} rows\")\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_data, df_details):\n",
    "    \"\"\"\n",
    "    Clean the sales and details dataframes by removing rows with missing values\n",
    "    and resetting the index.\n",
    "\n",
    "    Parameters:\n",
    "    df_data (pd.DataFrame): The sales dataframe.\n",
    "    df_details (pd.DataFrame): The details dataframe.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: The cleaned sales and details dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select relevant columns\n",
    "    df_data, df_details = select_columns(df_data, df_details)\n",
    "    \n",
    "    # Merge the dataframes to get more details\n",
    "    df_data = get_matched_models(df_data, df_details)\n",
    "    df_data = df_data[~df_data['matched_make'].isnull() & ~df_data['matched_model'].isnull()]\n",
    "\n",
    "    df_data = pd.merge(\n",
    "        df_data,\n",
    "        df_details.drop_duplicates(subset=['make', 'model', 'year']),\n",
    "        left_on=['matched_make', 'matched_model', 'year'],\n",
    "        right_on=['make', 'model', 'year'],\n",
    "        how='left',\n",
    "        suffixes=('', '_details')\n",
    "    )\n",
    "    df_data.drop(columns=['matched_make', 'matched_model', 'make', 'model_details'], inplace=True)\n",
    "    \n",
    "    # Impute missing values\n",
    "    numeric_columns = df_data.select_dtypes(include=[np.number]).columns\n",
    "    categorical_columns = df_data.select_dtypes(include=[object]).columns\n",
    "    \n",
    "    # Fill missing numeric values with the median\n",
    "    # df_data[numeric_columns] = df_data[numeric_columns].fillna(df_data[numeric_columns].median())\n",
    "\n",
    "    # Fill missing categorical values with the mode\n",
    "    # df_data[categorical_columns] = df_data[categorical_columns].fillna(df_data[categorical_columns].mode().iloc[0])\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_sales = clean_data(sample_df_sales, df_car_details)\n",
    "sample_df_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical columns\n",
    "numeric_columns = sample_df_sales.select_dtypes(include=[np.number]).columns\n",
    "categorical_columns = sample_df_sales.select_dtypes(include=[object]).columns\n",
    "encoded_sample_df = sample_df_sales.copy()\n",
    "\n",
    "# Encode categorical columns\n",
    "encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    encoded_sample_df[col] = le.fit_transform(encoded_sample_df[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = encoded_sample_df.corr()\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "# Show correlation with 'price'\n",
    "print(correlation_matrix['price'].apply(lambda x: abs(x)).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_sales.to_csv('../dataset/cleaned_sales_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
